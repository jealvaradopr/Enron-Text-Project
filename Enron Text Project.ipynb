{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>This project focuses on extracting words from a 1993 Enron 10K document.\n",
    "Most of the words should match one of three different lists of Loughran-McDonald sentiment of negative, litigious and uncertain words.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1: </b>Import negative word list, uncertainty word list, and litigious word list into Python as three separate lists ($list\\_neg$, $list\\_unc$, $list\\_lit$). Print the length of each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Input(filename):\n",
    "    f = open(filename, 'r')\n",
    "    text = f.read()                             # Reads entire file into one long string (containing line breaks)\n",
    "    words = text.replace('\\n',' ').split(' ')  # Converts string into list by splitting on ' '\n",
    "    words = [w for w in words if w != '']      #drops empty strings\n",
    "    f.close()\n",
    "    return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'HW6_Enron_10K_19931231.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-796da3031ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HW6_Enron_10K_19931231.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#prior function in use for Enron document and sentiment words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.6_LM_negative.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0munc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.6_LM_uncertainty.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.6_LM_litigious.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-27b1646eee2e>\u001b[0m in \u001b[0;36mInput\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m# Reads entire file into one long string (containing line breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Converts string into list by splitting on ' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;31m#drops empty strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HW6_Enron_10K_19931231.txt'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "doc = Input('HW6_Enron_10K_19931231.txt') #prior function in use for Enron document and sentiment words\n",
    "neg = Input('1.6_LM_negative.txt')\n",
    "unc = Input('1.6_LM_uncertainty.txt')\n",
    "lit = Input('1.6_LM_litigious.txt')\n",
    "\n",
    "list_neg = []     #list of negative words\n",
    "for w in neg: \n",
    "    list_neg.append(w) \n",
    "    \n",
    "list_unc = []     #list of uncertain words \n",
    "for w in unc: \n",
    "    list_unc.append(w)\n",
    "\n",
    "            \n",
    "list_lit = []     #list of litigious words\n",
    "for w in lit: \n",
    "    list_lit.append(w)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_neg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e7d6c59c1327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"list_neg:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"list_unc:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_unc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"list_lit:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_lit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#prints out the length of the lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_neg' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"list_neg:\", len(list_neg))\n",
    "print(\"list_unc:\", len(list_unc))\n",
    "print(\"list_lit:\", len(list_lit)) #prints out the length of the lists "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2:</b> Use a for loop or list comprehension to drop any words from the negative word list that appear in the uncertainty or litigious word lists. Similarly, use a for loop or list comprehension to drop any words from the uncertainty word list that also appear in the litigious word list. Name the new lists $list\\_neg2, list\\_unc2,$ and $list\\_lit2$. Print the length of each list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_neg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d54d607fc5bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist_neg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m           \u001b[0;31m#new list of non-overlapping negative words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_neg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_unc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_lit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlist_neg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlist_unc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m           \u001b[0;31m#new list of non-overlapping uncertain words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_neg' is not defined"
     ]
    }
   ],
   "source": [
    "list_neg2 = []           #new list of non-overlapping negative words\n",
    "for w in list_neg:  \n",
    "    if w not in list_unc and w not in list_lit: \n",
    "        list_neg2.append(w)\n",
    "list_unc2 = []           #new list of non-overlapping uncertain words\n",
    "list_lit2 = []           #new list of non-overlapping litigious words\n",
    "for w in list_unc: \n",
    "    if w not in list_lit:  \n",
    "            list_unc2.append(w)\n",
    "for w in list_lit: \n",
    "    list_lit2.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_neg2: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'list_unc2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d8887b8219ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"list_neg2:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_neg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"list_unc2:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_unc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"list_lit2:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_lit2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_unc2' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"list_neg2:\", len(list_neg2))\n",
    "print(\"list_unc2:\", len(list_unc2))\n",
    "print(\"list_lit2:\", len(list_lit2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3:</b> Import the document assigned to you as a single string. Use <b>.replace()</b> to remove all punctuation (i.e., ',' '.' '-' ';' ':' '!' '?' '(' ')' '[' ']') and tabs (i.e. \\t) and line returns (i.e. \\n). Use <b>.split()</b> and <b>.upper()</b> to convert the string into a list of uppercase words. Name this list $filing\\_w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'HW6_Enron_10K_19931231.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c11bea9ad9e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HW6_Enron_10K_19931231.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HW6_Enron_10K_19931231.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#opens the Enron document that has been formed in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-27b1646eee2e>\u001b[0m in \u001b[0;36mInput\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m# Reads entire file into one long string (containing line breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Converts string into list by splitting on ' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;31m#drops empty strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HW6_Enron_10K_19931231.txt'"
     ]
    }
   ],
   "source": [
    "doc = Input('HW6_Enron_10K_19931231.txt') \n",
    "x = open('HW6_Enron_10K_19931231.txt', 'r') #opens the Enron document that has been formed in a list\n",
    "text = x.read() \n",
    "text = text.replace(',', ' ')\n",
    "text = text.replace('.',' ')\n",
    "text = text.replace('-', ' ')\n",
    "text = text.replace(';', ' ')\n",
    "text = text.replace(':', ' ')\n",
    "text = text.replace('!', ' ')\n",
    "text = text.replace('?', ' ')\n",
    "text = text.replace('(', ' ')\n",
    "text = text.replace(')', ' ')\n",
    "text = text.replace('[', ' ')  \n",
    "text = text.replace(']', ' ')\n",
    "text = text.replace('\\t', ' ') \n",
    "text = text.replace('\\n', ' ') \n",
    "text = text.replace('<', ' ')\n",
    "text = text.replace('/', ' ') \n",
    "text = text.replace('>', ' ')\n",
    "filing_w = text.upper().split() #new list with punctuations removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 4:</b> Create the dictionary $dcount$ and use it to count how often each of the words on the three word lists appears in your document. Your dictionary does not need to include any word list words that do not appear in your document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_lit2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8717266bc598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdcount1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_lit2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdcount1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_lit2' is not defined"
     ]
    }
   ],
   "source": [
    "dcount1 = {}                 #new dictionary dcount1\n",
    "for w in list_neg2:          #all lists will start with words with 0 value\n",
    "    dcount1.setdefault(w, 0) \n",
    "     \n",
    "for w in list_lit2: \n",
    "    dcount1.setdefault(w, 0)\n",
    "     \n",
    "for w in list_unc2: \n",
    "    dcount1.setdefault(w, 0)\n",
    "    \n",
    "for w in filing_w:          #dictionary is counting repeated words \n",
    "    if w in dcount1: \n",
    "        dcount1[w] += 1 \n",
    "    \n",
    "dcount = {}                 #transferring the keys of dcount1 to new dictionary dcount \n",
    "for keys in dcount1: \n",
    "    if dcount1[keys] > 0: \n",
    "        dcount[keys] = dcount1[keys] \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 5:</b> Create a new list $list\\_tup$ containing tuples of the form ($word$, $type$, $count$), where $word$ is a word in the three word lists, $type$ is 'Negative', 'Uncertainty', or 'Litiguious', and $count$ is the count of each word in your document. The list should only contain words that appear at least once in your document. Words should be lowercase except for the first letter, which is capitalized. You should use the code below to print the first ten tuples in the sorted list.\n",
    "\n",
    "If helpful, you are welcome to create a separate dictionary that maps each word list word to 'Negative', Litigious', or 'Uncertainty'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dneg = {}     #new dictionary of negative words\n",
    "list_tup = []\n",
    "for w in list_neg2: \n",
    "    dneg.setdefault(w, 0)\n",
    "dunc = {}     #new dictionary of uncertain words\n",
    "for w in list_unc2: \n",
    "    dunc.setdefault(w, 0)\n",
    "dlit = {}     #new dictionary of litigious words \n",
    "for w in list_lit2: \n",
    "    dlit.setdefault(w, 0) \n",
    "    \n",
    "for w in dcount: \n",
    "    sub = [] #new list that appends variable word\n",
    "    word = w[0] + w[1:].lower() \n",
    "    sub.append(word) \n",
    "    if w in dneg: #appending overlapping words\n",
    "        sub.append('Negative') \n",
    "    elif w in dunc: \n",
    "        sub.append('Uncertain') \n",
    "    else: \n",
    "        sub.append('Litigious') \n",
    "    sub.append(dcount[w]) #adding the amount of times appeared \n",
    "    tup = tuple(sub) \n",
    "    list_tup.append(tup) #list of tuples appended "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 6:</b> Create a new list $list\\_top$ that contains the tuples of the ten most frequent words of each type ('Negative', 'Litigious', 'Uncertain') sorted from most frequent to least frequent. In other words, this list should consist of 30 tuples, where ten tuples are for the most frequent 'Negative' words, another ten tuples are for the most frequent 'Uncertainty', and the last ten tuples are for the most frequent 'Litigious'. Do not worry about including additional words if the tenth-most frequent word has the same count as the eleventh-most frequent word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_top = [] #new list of tuples of frequent words sorted \n",
    "negs = []\n",
    "lits = []\n",
    "uncs = [] \n",
    "\n",
    "def thirdval(tup): #function that returns amount of times the word in question is used \n",
    "    return tup[2] \n",
    "    \n",
    "\n",
    "for tup in list_tup: #for loop that appends list of corresponding type of words \n",
    "    if tup[1] == 'Negative': \n",
    "        negs.append(tup)\n",
    "    if tup[1] == 'Litigious': \n",
    "        lits.append(tup)\n",
    "    if tup[1] == 'Uncertain': \n",
    "        uncs.append(tup) \n",
    "        \n",
    "negs.sort(reverse = True, key=thirdval) #sorting the list of type of words using the function above\n",
    "lits.sort(reverse = True, key=thirdval)\n",
    "uncs.sort(reverse = True, key=thirdval) \n",
    "\n",
    "list_top = uncs[:10] + lits[:10] + negs[:10] #list of most frequent 10 words of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in list_top: #results\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Step 7: </b>Use <b>re.findall()</b> to find all of the numbers in your filing and print the largest number. Numbers like '0005000' should be treated as '5000'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "div = ' '.join(filing_w) \n",
    "num = re.findall(r'\\s([0-9]+)\\s', div) #re function using regular expressions\n",
    "n = [int(ele) for ele in num] #list comprehension in turning numbers found into integers \n",
    "\n",
    "largest = 0 \n",
    "for a in n: #for loop used to find the largest number using a low value variable\n",
    "    if a > largest: \n",
    "        largest = a \n",
    "print(largest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 8:</b> Choose a word from any of the word lists that shows up only once in your document, and create a print statement containing this word.\n",
    "\n",
    "Next, please use <b>re.search()</b> to match a pattern that consists of your word list word, the ten words before, and the ten words after. <b>Print all 21 words as a single string.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"My word is: CANCELED\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ' '.join(filing_w) #joins the string that is the filing \n",
    "x = re.findall(r'\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W(CANCELED)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)\\W([A-Z]+)', y)\n",
    "for ele in x: #regular expression for 21 words\n",
    "    str(ele) #for loop that makes words into strings \n",
    "z = ' '.join(ele) #joined pattern\n",
    "print(z) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
